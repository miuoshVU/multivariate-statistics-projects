---
title: "Lab02: Klasyfikacja"
output: html_document
date: 'Semestr letni 2021/22'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
```

## Medical Cost Personal Datasets

### Load dataset

```{r}
insurance <- read.csv(file = 'insurance.csv')
attach(insurance)
(insurance)
```

Obliczenie korelacji zmiennych numerycznych (z wyłączeniem `sex`, `smoker` oraz `region`)
```{r cor}
cor(insurance[sapply(insurance, is.numeric)])
```
### Logistic regression

```{r logistic}
insurance$smoker <- as.factor(insurance$smoker)
dir_logistic <- list()
dir_logistic$fit <- glm(smoker ~. , 
                   family = binomial, data = insurance)
summary(dir_logistic$fit)
```

Na podstawie wyników można wnioskować, że największy wpływ na to czy ktoś jest palaczem (**smoker**) mają:

* wiek - ujemny wpływ
* bmi - podobny do wieku ujemny wpływ
* koszt ubezpieczenia - niewielki dodatni wpływ

Równocześnie najmniejsze dla przeanalizowanego zbioru znaczenie mają predyktory takie jak:

* płeć
* region
* czy posiada dzieci

Usuwając najmniej istotne predyktory z modelu zwiększamy jego interpretację

```{r}
dir_logistic <- list()
dir_logistic$fit <- glm(smoker ~ age + bmi + charges , 
                   family = binomial, data = insurance)
summary(dir_logistic$fit)
```

Przewidujemy prawdopodobieństwa oraz je zwracamy
```{r }
dir_logistic$probs <- predict(dir_logistic$fit, type = "response")
head(dir_logistic$probs)
```

Sprawdzamy kodowanie wartości kolumny `smoker`
```{r logisticContrasts}
contrasts(insurance$smoker)
```
Przypisanie do klas jest rozstrzygane za pomocą decyzyjnej reguły bayesowskiej
```{r logisticClass}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, "yes", "no")
```


Możemy sprawdzić jak poradził sobie model stosując tablicę pomyłek (confusion matrix)
```{r logisticConfusionMatrix}
dir_logistic$cm <- table(dir_logistic$predicted, insurance$smoker)
dir_logistic$cm
```

Współczynnik błędów sklasyfikowanych przez model
```{r logisticErrorRate}
(dir_logistic$cm[1, 2] + dir_logistic$cm[2, 1]) / sum(dir_logistic$cm)
```

Dzielimy zbiór danych na treningowy i testowy w stosunku 80/20
```{r trainAndTestSets}
set.seed(101) 
sample <- sample.int(n = nrow(insurance), size = floor(.8*nrow(insurance)), replace = F)
train <- insurance[sample, ]
test  <- insurance[-sample, ]
```


Regresja logistyczna dla zbioru treningowego
```{r logisticTrain}
rownames(train) <- 1:nrow(train) 
dir_log_t <- list()
dir_log_t$fit<- glm(as.factor(smoker) ~ age + bmi + charges, 
                   family = binomial, data = train)
summary(dir_log_t$fit)
```
Każdy z otrzymanych modeli regresji logistycznej wypadł zdecydowanie lepiej niż model zerowy (stały).

Przewidujemy wartości zbioru testowego dla otrzymanego modelu
```{r logisticPredictionTrain}
dir_log_t$probs <- predict(dir_log_t$fit, test, type = "response")
dir_log_t$predicted <- ifelse(dir_log_t$probs > 0.5, "yes", "no")
table(dir_log_t$predicted, test[, c("smoker")])
```

### LDA

```{r lda}
dir_lda <- list()
dir_lda$fit <- lda(smoker ~ age + bmi + charges , data = train)
dir_lda$fit
```

```{r ldaPredict}
dir_lda$predicted <- predict(dir_lda$fit, test)
table(dir_lda$predicted$class, test[, c("smoker")])
```
### QDA

```{r qda}
dir_qda <- list()
dir_qda$fit <- qda(smoker ~ age + bmi + charges , data = train)
dir_qda$fit
```

```{r qdaPredict}
dir_qda$predicted <- predict(dir_qda$fit, test)
table(dir_qda$predicted$class, test[, c("smoker")])
```
### KNN

```{r knn}
train <- insurance[sample, ]
test  <- insurance[-sample, ]
smoker_train <- train$smoker
smoker_test <- test$smoker
train <- train[1:nrow(train) , c("age", "bmi", "charges")]
test <- test[1:nrow(test) , c("age", "bmi", "charges")]
dir_knn_1 <- knn(train, test, smoker_train, k = sqrt(nrow(train)))
table(dir_knn_1, smoker_test)
```
Najlepiej poradziła sobie z naszym zbiorem danych regresja logistyczna. Niewiele gorzej wypadł klasyfikator QDA. KNN oraz LDA poradziły sobie bardzo podobnie, ale wypadły gorzej niż pozostałe modele.
